{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRZppFIsM+WM26jmLnJJCj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amatyaagrata/ConceptandTechnologyofAI/blob/main/Workshop5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Read and Observe the Dataset.\n",
        "2. Print top(5) and bottom(5) of the dataset {Hint: pd.head and pd.tail}.\n",
        "3. Print the Information of Datasets. {Hint: pd.info}.\n",
        "4. Gather the Descriptive info about the Dataset. {Hint: pd.describe}\n",
        "5. Split your data into Feature (X) and Label (Y)."
      ],
      "metadata": {
        "id": "xWSq92X2gFux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "jMAyWa0tnBUx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the data set."
      ],
      "metadata": {
        "id": "0dHash1LR9DA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"student.csv\")\n",
        "print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_xoLsytRdxe",
        "outputId": "5b05220d-abb9-49db-8d5f-ffbbae7e234d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Math  Reading  Writing\n",
            "0      48       68       63\n",
            "1      62       81       72\n",
            "2      79       80       78\n",
            "3      76       83       79\n",
            "4      59       64       62\n",
            "..    ...      ...      ...\n",
            "995    72       74       70\n",
            "996    73       86       90\n",
            "997    89       87       94\n",
            "998    83       82       78\n",
            "999    66       66       72\n",
            "\n",
            "[1000 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print top 5 and bottom 5"
      ],
      "metadata": {
        "id": "xgXUUfZGSBET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Top 5 Records:\")\n",
        "print(data.head())\n",
        "\n",
        "print(\"Bottom 5 Records:\")\n",
        "print(data.tail())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa4fNiKFSAB4",
        "outputId": "40db38d2-66bc-4a3f-8a9a-bbc1c8da1cf8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Records:\n",
            "   Math  Reading  Writing\n",
            "0    48       68       63\n",
            "1    62       81       72\n",
            "2    79       80       78\n",
            "3    76       83       79\n",
            "4    59       64       62\n",
            "Bottom 5 Records:\n",
            "     Math  Reading  Writing\n",
            "995    72       74       70\n",
            "996    73       86       90\n",
            "997    89       87       94\n",
            "998    83       82       78\n",
            "999    66       66       72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Information"
      ],
      "metadata": {
        "id": "rEbsAh-hSMA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset Information:\")\n",
        "data.info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z192mfGjSP6T",
        "outputId": "053809c8-28fc-473d-ecad-7c7f3b395a85"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype\n",
            "---  ------   --------------  -----\n",
            " 0   Math     1000 non-null   int64\n",
            " 1   Reading  1000 non-null   int64\n",
            " 2   Writing  1000 non-null   int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 23.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descriptive Statistics."
      ],
      "metadata": {
        "id": "_89nm7rISUC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Descriptive Statistics:\")\n",
        "print(data.describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuaQK7aWSaJR",
        "outputId": "a93530b3-bb82-41fc-a38d-e082d8c688f5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descriptive Statistics:\n",
            "              Math      Reading      Writing\n",
            "count  1000.000000  1000.000000  1000.000000\n",
            "mean     67.290000    69.872000    68.616000\n",
            "std      15.085008    14.657027    15.241287\n",
            "min      13.000000    19.000000    14.000000\n",
            "25%      58.000000    60.750000    58.000000\n",
            "50%      68.000000    70.000000    69.500000\n",
            "75%      78.000000    81.000000    79.000000\n",
            "max     100.000000   100.000000   100.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split Feature(X) and Label(Y)"
      ],
      "metadata": {
        "id": "jC8Zs8TxSeH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[['Math', 'Reading']].values   # Feature Matrix\n",
        "Y = data['Writing'].values             # Target Vector\n"
      ],
      "metadata": {
        "id": "jscQFFTIStjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Matrix Formulation (No Bias Term)\n",
        "We assume not interception(bias=0)"
      ],
      "metadata": {
        "id": "OOHCl2C7YLbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Original feature matrix from dataset (n x d)\n",
        "X_raw = data[['Math', 'Reading']].values   # shape: (n, d)\n",
        "\n",
        "# Transpose to match worksheet definition (d x n)\n",
        "X = X_raw.T                                # shape: (d, n)\n",
        "\n",
        "# Target vector\n",
        "Y = data['Writing'].values                # shape: (n,)\n",
        "\n",
        "# Initialize weight vector (no bias)\n",
        "d = X.shape[0]\n",
        "W = np.zeros(d)                            # shape: (d,)\n"
      ],
      "metadata": {
        "id": "JATCUzTmXO3N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction using matrix form\n",
        "Y_pred = np.dot(W.T, X)   # shape: (n,)\n",
        "\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of W:\", W.shape)\n",
        "print(\"Shape of Y_pred:\", Y_pred.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVqK9IBGXTlB",
        "outputId": "57cac394-ae80-47eb-94e6-36ad9ffbd81d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (2, 1000)\n",
            "Shape of W: (2,)\n",
            "Shape of Y_pred: (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Train-test split"
      ],
      "metadata": {
        "id": "t_GucgN5YWGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X_raw, Y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "52hVoq4oYaPm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cost function (Main Square Error)"
      ],
      "metadata": {
        "id": "JSqEjWGcYwu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_function(X, Y, W):\n",
        "    \"\"\"\n",
        "    Computes Mean Squared Error cost\n",
        "    \"\"\"\n",
        "    n = len(Y)\n",
        "    Y_pred = np.dot(X, W)\n",
        "    cost = (1 / (2 * n)) * np.sum((Y_pred - Y) ** 2)\n",
        "    return cost\n"
      ],
      "metadata": {
        "id": "E0avdqDeY7fP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Function"
      ],
      "metadata": {
        "id": "wo8n_58HZMEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Case\n",
        "X_test_case = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "Y_test_case = np.array([3, 7, 11])\n",
        "W_test_case = np.array([1, 1])\n",
        "\n",
        "cost = cost_function(X_test_case, Y_test_case, W_test_case)\n",
        "\n",
        "if cost == 0:\n",
        "    print(\"Proceed Further\")\n",
        "else:\n",
        "    print(\"Something went wrong\")\n",
        "\n",
        "print(\"Cost function output:\", cost)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yoKJXN0ZPeG",
        "outputId": "188194d3-67fe-492c-cd73-b9912c53dbf0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proceed Further\n",
            "Cost function output: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradeant Desecnt Implementation"
      ],
      "metadata": {
        "id": "1XsFLSuVZgVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, Y, W, alpha, iterations):\n",
        "    \"\"\"\n",
        "    Performs Gradient Descent for Linear Regression\n",
        "    \"\"\"\n",
        "    cost_history = [0] * iterations\n",
        "    m = len(Y)\n",
        "\n",
        "    for i in range(iterations):\n",
        "        # Step 1: Predictions\n",
        "        Y_pred = np.dot(X, W)\n",
        "\n",
        "        # Step 2: Loss\n",
        "        loss = Y_pred - Y\n",
        "\n",
        "        # Step 3: Gradient\n",
        "        dw = (1 / m) * np.dot(X.T, loss)\n",
        "\n",
        "        # Step 4: Update Weights\n",
        "        W = W - alpha * dw\n",
        "\n",
        "        # Step 5: Cost\n",
        "        cost_history[i] = cost_function(X, Y, W)\n",
        "\n",
        "    return W, cost_history\n"
      ],
      "metadata": {
        "id": "mkWwTq71Zkg9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Code for gradient Descant Function"
      ],
      "metadata": {
        "id": "AK0rQbuUZs_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "X = np.random.rand(100, 3)\n",
        "Y = np.random.rand(100)\n",
        "W = np.random.rand(3)\n",
        "\n",
        "alpha = 0.01\n",
        "iterations = 1000\n",
        "\n",
        "final_params, cost_history = gradient_descent(X, Y, W, alpha, iterations)\n",
        "\n",
        "print(\"Final Parameters:\", final_params)\n",
        "print(\"Cost History (first 10):\", cost_history[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7KkjYT7Zsow",
        "outputId": "8c08155e-a07b-4852-be86-7a2eda5811d2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Parameters: [0.20551667 0.54295081 0.10388027]\n",
            "Cost History (first 10): [np.float64(0.10711197094660153), np.float64(0.10634880599939901), np.float64(0.10559826315680618), np.float64(0.10486012948320558), np.float64(0.1041341956428534), np.float64(0.10342025583900626), np.float64(0.1027181077540776), np.float64(0.1020275524908062), np.float64(0.10134839451441931), np.float64(0.1006804415957737)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation Matrics\n",
        "Root Mean Squared Error (RMSE)"
      ],
      "metadata": {
        "id": "Wbx7i2GuaBwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(Y, Y_pred):\n",
        "    rmse = np.sqrt(np.mean((Y - Y_pred) ** 2))\n",
        "    return rmse\n"
      ],
      "metadata": {
        "id": "G70PLot4Z6M9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "R-Squared"
      ],
      "metadata": {
        "id": "d_5f4R4-aIvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def r2(Y, Y_pred):\n",
        "    mean_y = np.mean(Y)\n",
        "    ss_tot = np.sum((Y - mean_y) ** 2)\n",
        "    ss_res = np.sum((Y - Y_pred) ** 2)\n",
        "    r2_score = 1 - (ss_res / ss_tot)\n",
        "    return r2_score\n"
      ],
      "metadata": {
        "id": "9kTSAKCTZ_yh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Function\n"
      ],
      "metadata": {
        "id": "pJTaFAUIa93a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Load dataset\n",
        "    data = pd.read_csv(\"student.csv\")\n",
        "\n",
        "    # Feature and Target\n",
        "    X = data[['Math', 'Reading']].values\n",
        "    Y = data['Writing'].values\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "        X, Y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Initialize parameters\n",
        "    W = np.zeros(X_train.shape[1])\n",
        "    alpha = 0.00001\n",
        "    iterations = 1000\n",
        "\n",
        "    # Train model\n",
        "    W_optimal, cost_history = gradient_descent(\n",
        "        X_train, Y_train, W, alpha, iterations\n",
        "    )\n",
        "\n",
        "    # Predictions\n",
        "    Y_pred = np.dot(X_test, W_optimal)\n",
        "\n",
        "    # Evaluation\n",
        "    model_rmse = rmse(Y_test, Y_pred)\n",
        "    model_r2 = r2(Y_test, Y_pred)\n",
        "\n",
        "    # Output\n",
        "    print(\"Final Weights:\", W_optimal)\n",
        "    print(\"Cost History (First 10):\", cost_history[:10])\n",
        "    print(\"RMSE:\", model_rmse)\n",
        "    print(\"R2 Score:\", model_r2)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iAZpupva_hG",
        "outputId": "1ee350b0-b6de-4359-82d9-e85e118f267f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Weights: [0.34811659 0.64614558]\n",
            "Cost History (First 10): [np.float64(2013.165570783755), np.float64(1640.286832599692), np.float64(1337.0619994901588), np.float64(1090.4794892850578), np.float64(889.9583270083234), np.float64(726.8940993009545), np.float64(594.2897260808594), np.float64(486.4552052951635), np.float64(398.7634463599484), np.float64(327.4517147324688)]\n",
            "RMSE: 5.2798239764188635\n",
            "R2 Score: 0.8886354462786421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Did your Model Overfitt, Underfitts, or performance is acceptable."
      ],
      "metadata": {
        "id": "qKpdCJbVbibR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model doesnot overfit(simple linear regression, few parameters). performance is acceptable:\n",
        "1. RMSE is low.\n",
        "2. R2 is reasonably close to 1\n",
        "3. Slightly underfitting may occur due to no bias term."
      ],
      "metadata": {
        "id": "eBOyKGK7bjpF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Experiment with different value of learning rate, making it higher and lower, observe the result."
      ],
      "metadata": {
        "id": "F3TtEbMGcG5D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Very Small(0.0000001)=>>Slow Convergence\n",
        "\n",
        "Optimal(0.00001)==>>Stable & Smooth\n",
        "\n",
        "Large(0.01+)=>>Cost oscillates or diverges\n",
        "\n",
        "Conlusion:Proper learning rate selection is crucial for convergence."
      ],
      "metadata": {
        "id": "byxBehCJcHn8"
      }
    }
  ]
}